{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Debugging Assistant with Episodic Memory\n",
    "\n",
    "## Overview\n",
    "\n",
    "This notebook demonstrates how to build an intelligent **Debugging Assistant** using **AgentCore Episodic Memory** with reflections. The agent learns from past debugging sessions and provides context-aware guidance based on historical experiences.\n",
    "\n",
    "### What is Episodic Memory?\n",
    "\n",
    "**Episodic Memory** captures complete interaction sequences (episodes) with structured context. Unlike semantic memory which stores isolated facts, episodic memory preserves:\n",
    "- **Full conversation flows**: Complete debugging sessions from problem statement to resolution\n",
    "- **Temporal context**: The sequence and timing of actions taken\n",
    "- **Outcomes**: Whether the debugging attempt succeeded or failed\n",
    "- **Structured turns**: Individual steps with thoughts, actions, and observations\n",
    "\n",
    "![Episodic memory](./episodic_memory.png)\n",
    "\n",
    "### What are Reflections?\n",
    "\n",
    "**Reflections** are synthesized insights automatically extracted from multiple episodes. They provide:\n",
    "- **Pattern recognition**: Common issues and their solutions across similar episodes\n",
    "- **Best practices**: What strategies worked well in successful debugging sessions\n",
    "- **Common pitfalls**: Mistakes to avoid based on failed attempts\n",
    "- **Strategic guidance**: High-level advice for approaching similar problems\n",
    "\n",
    "**Output Structure:**\n",
    "- **Episodes**: Stored in `debugging/{actorId}/sessions/{sessionId}` - Full conversation traces\n",
    "- **Reflections**: Stored in `debugging/{actorId}` - Synthesized knowledge from multiple episodes\n",
    "\n",
    "### When to Use Episodic Memory?\n",
    "\n",
    "Use episodic memory when:\n",
    "1. **Sequential context matters**: The order of actions and their outcomes is important (e.g., debugging workflows, troubleshooting procedures)\n",
    "2. **Learning from experience**: You want the agent to improve by analyzing past successes and failures\n",
    "3. **Process retrieval**: Users need to recall \"how did I solve X last time?\" or \"show me the exact steps taken\"\n",
    "\n",
    "### Tutorial Details\n",
    "\n",
    "| Information | Details |\n",
    "|:------------|:--------|\n",
    "| Tutorial type | Episodic Memory with Reflections |\n",
    "| Agent type | Debugging Assistant |\n",
    "| Framework | Strands Agents |\n",
    "| LLM model | Claude Haiku 4.5 |\n",
    "| Memory strategies | Episodic Memory with Reflection Configuration |\n",
    "| Complexity | Intermediate |\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "- Python 3.10+\n",
    "- AWS credentials with AgentCore Memory permissions\n",
    "- Access to AgentCore services"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Install Dependencies and Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-26T16:58:42.906886Z",
     "iopub.status.busy": "2025-11-26T16:58:42.906491Z",
     "iopub.status.idle": "2025-11-26T16:58:45.067060Z",
     "shell.execute_reply": "2025-11-26T16:58:45.065712Z",
     "shell.execute_reply.started": "2025-11-26T16:58:42.906851Z"
    }
   },
   "outputs": [],
   "source": [
    "%pip install -qr requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-26T22:51:58.771618Z",
     "iopub.status.busy": "2025-11-26T22:51:58.771345Z",
     "iopub.status.idle": "2025-11-26T22:51:59.351162Z",
     "shell.execute_reply": "2025-11-26T22:51:59.350299Z",
     "shell.execute_reply.started": "2025-11-26T22:51:58.771589Z"
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import logging\n",
    "import sys\n",
    "import uuid\n",
    "from datetime import datetime, timezone\n",
    "from typing import List, Dict, Any\n",
    "from pprint import pprint\n",
    "\n",
    "# Setup logging\n",
    "logging.basicConfig(level=logging.INFO, format=\"%(asctime)s - %(levelname)s - %(message)s\")\n",
    "logger = logging.getLogger(\"debugging-assistant\")\n",
    "\n",
    "# Import boto3 for control plane and data plane operations\n",
    "import boto3\n",
    "\n",
    "# Import Strands Agent framework\n",
    "from strands import Agent, tool\n",
    "\n",
    "logger.info(\"‚úÖ All dependencies imported successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2025-11-26T22:51:59.855074Z",
     "iopub.status.busy": "2025-11-26T22:51:59.854778Z",
     "iopub.status.idle": "2025-11-26T22:51:59.863102Z",
     "shell.execute_reply": "2025-11-26T22:51:59.862200Z",
     "shell.execute_reply.started": "2025-11-26T22:51:59.855051Z"
    },
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "# Configuration\n",
    "REGION = os.getenv('AWS_REGION', 'us-west-2')\n",
    "# Session identifiers\n",
    "ACTOR_ID = \"developer\"\n",
    "\n",
    "logger.info(f\"Configuration set for region: {REGION}\")\n",
    "logger.info(f\"Actor ID: {ACTOR_ID}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Create Memory with Episodic Strategy\n",
    "\n",
    "We'll create a memory resource configured with **Episodic Memory Strategy** that includes **Reflection Configuration**. This enables:\n",
    "- Storing complete debugging session episodes\n",
    "- Automatic generation of reflection insights from multiple episodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize boto3 client for control and data plane operations\n",
    "client = boto3.client(\n",
    "    'bedrock-agentcore',\n",
    "    region_name=REGION,\n",
    ")\n",
    "memory_client = boto3.client(\n",
    "  'bedrock-agentcore-control',\n",
    "   region_name=REGION,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-26T22:52:01.937639Z",
     "iopub.status.busy": "2025-11-26T22:52:01.937295Z",
     "iopub.status.idle": "2025-11-26T22:52:01.944616Z",
     "shell.execute_reply": "2025-11-26T22:52:01.943730Z",
     "shell.execute_reply.started": "2025-11-26T22:52:01.937612Z"
    }
   },
   "outputs": [],
   "source": [
    "# Define episodic memory strategy with reflections as dictionary\n",
    "memory_name = \"DebugAssistantEpisodic\"\n",
    "\n",
    "# Episodic memory is implemented as a customMemoryStrategy\n",
    "episodic_strategy = {\n",
    "    \"episodicMemoryStrategy\": {\n",
    "      \"name\": \"DebuggingEpisodeExtractor\",\n",
    "      \"description\": \"Creates debugging session episodes with reflections per actor\",\n",
    "      \"namespaces\": [\n",
    "        \"debugging/{actorId}/sessions/{sessionId}\"\n",
    "      ],\n",
    "      \"reflectionConfiguration\": {\n",
    "        \"namespaces\": [\n",
    "          \"debugging/{actorId}\" # should be an exact prefix of the episodic memory namespace.\n",
    "        ]\n",
    "      }\n",
    "    }\n",
    "}\n",
    "logger.info(f\"Strategy configured: {episodic_strategy['episodicMemoryStrategy']['name']}\")\n",
    "logger.info(f\"Episode namespace: {episodic_strategy['episodicMemoryStrategy']['namespaces'][0]}\")\n",
    "logger.info(f\"Reflection namespace: {episodic_strategy['episodicMemoryStrategy']['reflectionConfiguration']['namespaces'][0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-26T22:52:02.950595Z",
     "iopub.status.busy": "2025-11-26T22:52:02.950298Z",
     "iopub.status.idle": "2025-11-26T22:52:03.580439Z",
     "shell.execute_reply": "2025-11-26T22:52:03.579576Z",
     "shell.execute_reply.started": "2025-11-26T22:52:02.950573Z"
    }
   },
   "outputs": [],
   "source": [
    "# Get or create memory\n",
    "try:\n",
    "    # Try to find existing memory first\n",
    "    list_response = memory_client.list_memories(maxResults=100)\n",
    "    memory_id = None\n",
    "    for mem in list_response.get('memories', []):\n",
    "        detail = memory_client.get_memory(memoryId=mem['id'])\n",
    "        if detail['memory'].get('name') == memory_name:\n",
    "            memory_id = mem['id']\n",
    "            logger.info(f\"‚úÖ Using existing memory: {memory_id}\")\n",
    "            break\n",
    "    \n",
    "    # Create if not found\n",
    "    if not memory_id:\n",
    "        logger.info(f\"Creating new memory: {memory_name}\")\n",
    "        response = memory_client.create_memory(\n",
    "            name=memory_name,\n",
    "            description=\"Episodic memory for debugging assistant with reflections\",\n",
    "            eventExpiryDuration=90,\n",
    "            memoryStrategies=[episodic_strategy],\n",
    "            clientToken=str(uuid.uuid4())\n",
    "        )\n",
    "        memory_id = response['memory']['id']\n",
    "        logger.info(f\"‚úÖ Memory created: {memory_id}\")\n",
    "        \n",
    "        # Wait for ACTIVE\n",
    "        import time\n",
    "        for _ in range(30):\n",
    "            status = memory_client.memory_get_memory(memoryId=memory_id)['memory']['status']\n",
    "            if status == 'ACTIVE':\n",
    "                logger.info(\"‚úÖ Memory is ACTIVE\")\n",
    "                break\n",
    "            time.sleep(10)\n",
    "            \n",
    "except Exception as e:\n",
    "    logger.error(f\"‚ùå Failed to get/create memory: {e}\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Hydrate Memory with Historical Debugging Sessions\n",
    "\n",
    "Let's load past debugging sessions into episodic memory. Each session represents a complete debugging workflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-26T22:52:08.133717Z",
     "iopub.status.busy": "2025-11-26T22:52:08.133438Z",
     "iopub.status.idle": "2025-11-26T22:52:09.541470Z",
     "shell.execute_reply": "2025-11-26T22:52:09.540860Z",
     "shell.execute_reply.started": "2025-11-26T22:52:08.133694Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "\n",
    "# Load all session data files\n",
    "data_dir = \"./data\"\n",
    "session_files = sorted(glob.glob(f\"{data_dir}/*.json\"))\n",
    "\n",
    "logger.info(f\"Found {len(session_files)} session files to hydrate\")\n",
    "\n",
    "# Hydrate each session\n",
    "for session_file in session_files:\n",
    "    session_name = os.path.basename(session_file).replace('.json', '')\n",
    "    session_id = f\"{session_name}_{datetime.now().strftime('%Y%m%d%H%M%S')}\"\n",
    "    \n",
    "    logger.info(f\"Hydrating session: {session_name}\")\n",
    "    \n",
    "    # Load conversation data\n",
    "    with open(session_file, 'r') as f:\n",
    "        conversation = json.load(f)\n",
    "    \n",
    "    # Convert to payload format\n",
    "    payload = []\n",
    "    for turn in conversation:\n",
    "        conv_data = turn['conversational']\n",
    "        payload.append({\n",
    "            'conversational': {\n",
    "                'content': {'text': conv_data['content']['text']},\n",
    "                'role': conv_data['role']\n",
    "            }\n",
    "        })\n",
    "    \n",
    "    # Create event using boto3 directly\n",
    "    event_timestamp = datetime.now(timezone.utc)\n",
    "    result = client.create_event(\n",
    "        memoryId=memory_id,\n",
    "        actorId=ACTOR_ID,\n",
    "        sessionId=session_id,\n",
    "        eventTimestamp=event_timestamp,\n",
    "        payload=payload\n",
    "    )\n",
    "\n",
    "    logger.info(f\"   ‚úì Stored {len(payload)} turns - Event ID: {result['event']['eventId']}\")\n",
    "\n",
    "logger.info(f\"‚úÖ Successfully hydrated {len(session_files)} debugging sessions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-26T23:16:10.209423Z",
     "iopub.status.busy": "2025-11-26T23:16:10.209150Z",
     "iopub.status.idle": "2025-11-26T23:16:10.942298Z",
     "shell.execute_reply": "2025-11-26T23:16:10.941595Z",
     "shell.execute_reply.started": "2025-11-26T23:16:10.209400Z"
    }
   },
   "outputs": [],
   "source": [
    "### list memory records to see if its been extracted to LTM\n",
    "import time\n",
    "import pprint\n",
    "reflection_namespace = f\"debugging/{ACTOR_ID}\"\n",
    "# time.sleep(60)\n",
    "# Use boto3 client directly to retrieve memory records\n",
    "response = client.list_memory_records(\n",
    "    memoryId=memory_id,\n",
    "    namespace=reflection_namespace,\n",
    "    maxResults=20\n",
    ")\n",
    "memories = response.get('memoryRecordSummaries', [])\n",
    "logger.info(f\"   Found {len(memories)} memories\")\n",
    "if memories:\n",
    "    pprint.pp(json.loads(memories[0][\"content\"][\"text\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-26T23:16:30.118738Z",
     "iopub.status.busy": "2025-11-26T23:16:30.118469Z",
     "iopub.status.idle": "2025-11-26T23:16:30.392365Z",
     "shell.execute_reply": "2025-11-26T23:16:30.391697Z",
     "shell.execute_reply.started": "2025-11-26T23:16:30.118717Z"
    }
   },
   "outputs": [],
   "source": [
    "# check if reflections and episodes have been generated or not.\n",
    "import pprint\n",
    "# Use boto3 client directly to retrieve memory records\n",
    "response = client.retrieve_memory_records(\n",
    "memoryId=memory_id,\n",
    "namespace=f\"debugging/{ACTOR_ID}\",\n",
    "searchCriteria={\n",
    "    'searchQuery': \"memory leaks\",\n",
    "    \"metadataFilters\":[{\"left\": {\"metadataKey\": \"x-amz-agentcore-memory-recordType\"},\n",
    "        \"operator\": \"EQUALS_TO\",\n",
    "        \"right\": {\"metadataValue\": {\"stringValue\": \"REFLECTION\"}}\n",
    "        }],          \n",
    "    'topK': 10\n",
    "},\n",
    "    maxResults=20\n",
    ")\n",
    "\n",
    "reflections = response.get('memoryRecordSummaries', [])\n",
    "logger.info(f\"   Found {len(reflections)} relevant reflections\")\n",
    "if reflections:\n",
    "    for reflection in reflections:\n",
    "        reflection_json = json.loads(reflection['content']['text'])\n",
    "        pprint.pp(reflection_json)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Create Memory Retrieval Tools\n",
    "\n",
    "We'll create two specialized tools for the agent:\n",
    "1. **retrieve_process**: Retrieves complete episode traces for detailed step-by-step processes\n",
    "2. **retrieve_reflection_knowledge**: Retrieves synthesized insights and patterns from multiple episodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-26T23:16:50.712898Z",
     "iopub.status.busy": "2025-11-26T23:16:50.712627Z",
     "iopub.status.idle": "2025-11-26T23:16:50.723074Z",
     "shell.execute_reply": "2025-11-26T23:16:50.722291Z",
     "shell.execute_reply.started": "2025-11-26T23:16:50.712878Z"
    }
   },
   "outputs": [],
   "source": [
    "def count_tokens(text: str) -> int:\n",
    "    \"\"\"Approximate token count for a text string.\"\"\"\n",
    "    return len(text)\n",
    "\n",
    "\n",
    "def linearize_episodes(episodes: List[Dict], include_steps: bool = True,\n",
    "                       include_reflections: bool = True) -> str:\n",
    "    \"\"\"Linearize episode data into human-readable format.\"\"\"\n",
    "    if not episodes:\n",
    "        return \"No relevant episodes found.\"\n",
    "\n",
    "    output = []\n",
    "    for idx, episode in enumerate(episodes, 1):\n",
    "        content = episode.get('content', {})\n",
    "        \n",
    "        # Parse JSON from text field\n",
    "        if 'text' in content:\n",
    "            try:\n",
    "                episode_data = json.loads(content['text'])\n",
    "            except json.JSONDecodeError:\n",
    "                output.append(f\"Episode {idx}: Unable to parse content\\n\")\n",
    "                continue\n",
    "        else:\n",
    "            output.append(f\"Episode {idx}: No content available\\n\")\n",
    "            continue\n",
    "        \n",
    "        output.append(f\"{'='*80}\\nEpisode {idx}\\n{'='*80}\")\n",
    "        output.append(f\"**Situation:** {episode_data.get('situation', 'N/A')}\")\n",
    "        output.append(f\"**Intent:** {episode_data.get('intent', 'N/A')}\")\n",
    "        output.append(f\"**Assessment:** {episode_data.get('assessment', 'N/A')}\\n\")\n",
    "        \n",
    "        if include_steps:\n",
    "            turns = episode_data.get('turns', [])\n",
    "            if turns:\n",
    "                output.append(\"**Debugging Steps:**\")\n",
    "                for turn_idx, turn in enumerate(turns, 1):\n",
    "                    output.append(f\"\\nStep {turn_idx}:\")\n",
    "                    output.append(f\"  Situation: {turn.get('situation', 'N/A')}\")\n",
    "                    output.append(f\"  Action: {turn.get('action', 'N/A')}\")\n",
    "                    output.append(f\"  Thought: {turn.get('thought', 'N/A')}\")\n",
    "        \n",
    "        if include_reflections:\n",
    "            reflection = episode_data.get('reflection')\n",
    "            if reflection:\n",
    "                output.append(f\"\\n**Reflection:** {reflection}\\n\")\n",
    "    \n",
    "    result = \"\\n\".join(output)\n",
    "    logger.info(f\"   Episode tokens: {count_tokens(result)}\")\n",
    "    return result\n",
    "\n",
    "\n",
    "def linearize_reflections(reflections: List[Dict]) -> str:\n",
    "    \"\"\"Linearize reflection knowledge into human-readable format.\"\"\"\n",
    "    if not reflections:\n",
    "        return \"No reflection knowledge found.\"\n",
    "\n",
    "    output = []\n",
    "    for idx, reflection in enumerate(reflections, 1):\n",
    "        content = reflection.get('content', {})\n",
    "        score = reflection.get('score', 0)\n",
    "        \n",
    "        # Parse JSON from text field\n",
    "        if 'text' in content:\n",
    "            try:\n",
    "                reflection_data = json.loads(content['text'])\n",
    "            except json.JSONDecodeError:\n",
    "                continue\n",
    "        else:\n",
    "            continue\n",
    "\n",
    "        output.append(f\"{'='*80}\\nReflection {idx} (Relevance: {score:.2f})\\n{'='*80}\")\n",
    "        output.append(f\"**Title:** {reflection_data.get('title', 'Untitled')}\")\n",
    "        output.append(f\"**Use Cases:** {reflection_data.get('use_cases', 'N/A')}\")\n",
    "        output.append(f\"**Hints:** {reflection_data.get('hints', 'N/A')}\\n\")\n",
    "    \n",
    "    result = \"\\n\".join(output)\n",
    "    logger.info(f\"   Reflection tokens: {count_tokens(result)}\")\n",
    "    return result\n",
    "\n",
    "\n",
    "logger.info(\"‚úÖ Linearization helper functions created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-26T23:16:55.455297Z",
     "iopub.status.busy": "2025-11-26T23:16:55.455029Z",
     "iopub.status.idle": "2025-11-26T23:16:55.468476Z",
     "shell.execute_reply": "2025-11-26T23:16:55.467848Z",
     "shell.execute_reply.started": "2025-11-26T23:16:55.455278Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create memory retrieval tools for the agent\n",
    "\n",
    "@tool\n",
    "def retrieve_process(task: str, include_steps: bool = True) -> str:\n",
    "    \"\"\"\n",
    "    Retrieve example processes to help solve the given task. Returns complete debugging\n",
    "    episodes with configurable detail level.\n",
    "    \n",
    "    Use include_steps parameter to control verbosity:\n",
    "    - Set include_steps=True when user asks for \"exact steps\", \"full details\", \"how did we\",\n",
    "      \"what steps did we take\", or needs complete procedural information\n",
    "    - Set include_steps=False for pattern/best practice queries where high-level context\n",
    "      (situation, intent, assessment) is sufficient without step-by-step details\n",
    "\n",
    "    Args:\n",
    "        task: The task to solve that requires example processes\n",
    "        include_steps: Whether to include detailed step-by-step turns (default: True)\n",
    "\n",
    "    Returns:\n",
    "        Formatted debugging episodes with optional detailed steps\n",
    "    \"\"\"\n",
    "    logger.info(f\"üîç Retrieving processes for task: {task} (include_steps={include_steps})\")\n",
    "    \n",
    "    try:\n",
    "        # Search in episode namespace\n",
    "        namespace = f\"debugging/{ACTOR_ID}/sessions/{session_id}\"\n",
    "        \n",
    "        # Use boto3 client directly to retrieve memory records\n",
    "        response = client.retrieve_memory_records(\n",
    "            memoryId=memory_id,\n",
    "            namespace=namespace,\n",
    "            searchCriteria={\n",
    "                'searchQuery': task,\n",
    "                'topK': 3\n",
    "            },\n",
    "            maxResults=20\n",
    "        )\n",
    "        \n",
    "        episodes = response.get('memoryRecordSummaries', [])\n",
    "        logger.info(f\"   Found {len(episodes)} relevant episodes\")\n",
    "        \n",
    "        # Linearize with configurable detail level\n",
    "        return linearize_episodes(episodes, include_steps=include_steps, include_reflections=True)\n",
    "        \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error retrieving processes: {e}\")\n",
    "        return f\"Error retrieving processes: {str(e)}\"\n",
    "\n",
    "\n",
    "@tool\n",
    "def retrieve_reflection_knowledge(task: str, k: int = 5) -> str:\n",
    "    \"\"\"\n",
    "    Retrieve synthesized reflection knowledge from past agent experiences. Each knowledge \n",
    "    entry contains: (1) a descriptive title, (2) specific use cases for when to apply it, \n",
    "    and (3) actionable hints including best practices from successful episodes and common \n",
    "    pitfalls to avoid from failed episodes. Use this to get strategic guidance and patterns\n",
    "    for similar tasks.\n",
    "\n",
    "    Args:\n",
    "        task: The current task to get strategic guidance for\n",
    "        k: Number of reflection entries to retrieve (default: 5)\n",
    "\n",
    "    Returns:\n",
    "        Synthesized reflection knowledge from past debugging experiences\n",
    "    \"\"\"\n",
    "    logger.info(f\"üîç Retrieving reflection knowledge for task: {task}\")\n",
    "    \n",
    "    try:\n",
    "        # Search in reflection namespace\n",
    "        namespace = f\"debugging/{ACTOR_ID}\"\n",
    "        \n",
    "        # Use boto3 client directly to retrieve memory records\n",
    "        response = client.retrieve_memory_records(\n",
    "            memoryId=memory_id,\n",
    "            namespace=namespace,\n",
    "            searchCriteria={\n",
    "                'searchQuery': \"memory leaks\",\n",
    "                \"metadataFilters\":[{\"left\":{\"metadataKey\": \"x-amz-agentcore-memory-recordType\"},\n",
    "                                    \"operator\": \"EQUALS_TO\",\n",
    "                                    \"right\": {\"metadataValue\": {\"stringValue\": \"REFLECTION\"}}\n",
    "                                    }],          \n",
    "                'topK': k\n",
    "            },\n",
    "            maxResults=20\n",
    "        )\n",
    "        \n",
    "        reflections = response.get('memoryRecordSummaries', [])\n",
    "        logger.info(f\"   Found {len(reflections)} relevant reflection insights\")\n",
    "        \n",
    "        # Linearize reflections\n",
    "        return linearize_reflections(reflections)\n",
    "        \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error retrieving reflections: {e}\")\n",
    "        return f\"Error retrieving reflections: {str(e)}\"\n",
    "\n",
    "\n",
    "logger.info(\"‚úÖ Memory retrieval tools created\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Create Debugging Assistant Agent\n",
    "\n",
    "Now we'll create a Strands agent equipped with our memory retrieval tools."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-26T23:16:57.666354Z",
     "iopub.status.busy": "2025-11-26T23:16:57.666076Z",
     "iopub.status.idle": "2025-11-26T23:16:57.736424Z",
     "shell.execute_reply": "2025-11-26T23:16:57.735681Z",
     "shell.execute_reply.started": "2025-11-26T23:16:57.666332Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create the debugging assistant agent\n",
    "debugging_agent = Agent(\n",
    "    model=\"global.anthropic.claude-haiku-4-5-20251001-v1:0\",\n",
    "    tools=[retrieve_process, retrieve_reflection_knowledge],\n",
    "    system_prompt=\"\"\"You are an expert Debugging Assistant with access to episodic memory.\n",
    "\n",
    "Your capabilities:\n",
    "- Retrieve past debugging episodes with complete step-by-step processes\n",
    "- Access synthesized reflection knowledge showing patterns and best practices\n",
    "- Provide guidance based on successful debugging experiences\n",
    "- Warn about common pitfalls observed in past failures\n",
    "\n",
    "When helping users:\n",
    "1. Use retrieve_reflection_knowledge for strategic guidance, patterns, and high-level advice\n",
    "2. Use retrieve_process when users need exact steps or want to recall what was done in a specific session\n",
    "3. Synthesize insights from memory with your own reasoning\n",
    "4. Be specific and actionable in your recommendations\n",
    "\n",
    "Always explain your reasoning and cite relevant past experiences when available.\"\"\"\n",
    ")\n",
    "\n",
    "logger.info(\"‚úÖ Debugging assistant agent created\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Test the Debugging Assistant\n",
    "\n",
    "Let's test various scenarios to see how the agent uses episodic memory and reflections."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test 1: Query for Strategic Guidance (Reflection Knowledge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-26T23:17:00.344523Z",
     "iopub.status.busy": "2025-11-26T23:17:00.344256Z",
     "iopub.status.idle": "2025-11-26T23:17:20.599748Z",
     "shell.execute_reply": "2025-11-26T23:17:20.598898Z",
     "shell.execute_reply.started": "2025-11-26T23:17:00.344503Z"
    }
   },
   "outputs": [],
   "source": [
    "# Test 1: Get strategic guidance for memory issues\n",
    "query1 = \"My application is running out of memory when processing large datasets. What should I look for?\"\n",
    "\n",
    "logger.info(f\"\\n{'='*80}\")\n",
    "logger.info(f\"Test 1: Memory Issue Guidance\")\n",
    "logger.info(f\"{'='*80}\")\n",
    "logger.info(f\"Query: {query1}\\n\")\n",
    "\n",
    "response1 = debugging_agent(query1)\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"AGENT RESPONSE:\")\n",
    "print(\"=\"*80)\n",
    "print(response1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test 2: Query for Specific Process Details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test 2: Get specific debugging process\n",
    "query2 = \"Show me the exact steps for debugging a timeout issue with external API calls.\"\n",
    "\n",
    "logger.info(f\"\\n{'='*80}\")\n",
    "logger.info(f\"Test 2: API Timeout Debugging Process\")\n",
    "logger.info(f\"{'='*80}\")\n",
    "logger.info(f\"Query: {query2}\\n\")\n",
    "\n",
    "response2 = debugging_agent(query2)\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"AGENT RESPONSE:\")\n",
    "print(\"=\"*80)\n",
    "print(response2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test 3: Query for Pattern Recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test 3: Get patterns and best practices for concurrency issues\n",
    "query3 = \"What are common patterns and best practices for handling race conditions in multi-threaded applications?\"\n",
    "\n",
    "logger.info(f\"\\n{'='*80}\")\n",
    "logger.info(f\"Test 3: Race Condition Patterns\")\n",
    "logger.info(f\"{'='*80}\")\n",
    "logger.info(f\"Query: {query3}\\n\")\n",
    "\n",
    "response3 = debugging_agent(query3)\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"AGENT RESPONSE:\")\n",
    "print(\"=\"*80)\n",
    "print(response3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test 4: Recall Specific Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test 4: Recall what was done in memory leak session\n",
    "query4 = \"What debugging steps did we take when we encountered the memory leak issue? I need the full details.\"\n",
    "\n",
    "logger.info(f\"\\n{'='*80}\")\n",
    "logger.info(f\"Test 4: Recall Memory Leak Session\")\n",
    "logger.info(f\"{'='*80}\")\n",
    "logger.info(f\"Query: {query4}\\n\")\n",
    "\n",
    "response4 = debugging_agent(query4)\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"AGENT RESPONSE:\")\n",
    "print(\"=\"*80)\n",
    "print(response4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 8: Direct Memory Inspection\n",
    "\n",
    "Let's directly inspect what's stored in episodic memory and reflections."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect episodes directly using boto3\n",
    "logger.info(\"\" + \"=\"*80)\n",
    "logger.info(\"Direct Episode Inspection\")\n",
    "logger.info(\"=\"*80)\n",
    "\n",
    "# Retrieve episodes using boto3 directly\n",
    "namespace = f\"debugging/{ACTOR_ID}/sessions\"\n",
    "response = client.retrieve_memory_records(\n",
    "    memoryId=memory_id,\n",
    "    namespace=namespace,\n",
    "    searchCriteria={\n",
    "        'searchQuery': 'debugging',\n",
    "        'topK': 2\n",
    "    },\n",
    "    maxResults=10\n",
    ")\n",
    "\n",
    "episodes = response.get('memoryRecordSummaries', [])\n",
    "\n",
    "print(f\"Found {len(episodes)} episodes in memory:\")\n",
    "for idx, episode in enumerate(episodes, 1):\n",
    "    print(f\"Episode {idx}:\")\n",
    "    pprint.pp(episode, depth=2, width=100)\n",
    "    print(\"-\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pprint\n",
    "response = client.retrieve_memory_records(\n",
    "memoryId=memory_id,\n",
    "namespace=reflection_namespace,\n",
    "searchCriteria={\n",
    "    'searchQuery': \"memory leaks\",\n",
    "    \"metadataFilters\":[{\n",
    "        \"left\":{\"metadataKey\": \"x-amz-agentcore-memory-recordType\"},\n",
    "        \"operator\": \"EQUALS_TO\",\n",
    "        \"right\": {\"metadataValue\": {\"stringValue\": \"REFLECTION\"}}\n",
    "                        }],          \n",
    "    'topK': 10\n",
    "},\n",
    "    maxResults=20\n",
    ")\n",
    "\n",
    "reflections = response.get('memoryRecordSummaries', [])\n",
    "logger.info(f\"   Found {len(reflections)} relevant reflections\")\n",
    "if reflections:\n",
    "    for reflection in reflections:\n",
    "        reflection_json = json.loads(reflection['content']['text'])\n",
    "        pprint.pp(reflection_json)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "### What We Accomplished\n",
    "\n",
    "‚úÖ Created episodic memory with reflection configuration using boto3\n",
    "\n",
    "‚úÖ Hydrated memory with historical debugging sessions\n",
    "\n",
    "‚úÖ Built specialized retrieval tools for episodes and reflections\n",
    "\n",
    "‚úÖ Created an intelligent debugging assistant using Strands framework\n",
    "\n",
    "‚úÖ Demonstrated strategic guidance retrieval vs. detailed process retrieval\n",
    "\n",
    "### Key Takeaways\n",
    "\n",
    "1. **Episodic Memory** preserves complete interaction sequences with temporal context\n",
    "2. **Reflections** automatically synthesize patterns and insights from multiple episodes\n",
    "3. **Linearization** optimizes context by formatting structured data for LLM consumption\n",
    "4. **Tool selection** matters: use reflections for strategy, episodes for detailed steps\n",
    "5. **Boto3 Direct Access** provides full control over Genesis Memory API operations\n",
    "\n",
    "### When to Use This Pattern\n",
    "\n",
    "- **Technical support systems** that learn from past ticket resolutions\n",
    "- **Troubleshooting assistants** that recall successful diagnostic procedures\n",
    "- **Training systems** that capture expert workflows for knowledge transfer\n",
    "- **Process improvement** scenarios where analyzing past outcomes drives better practices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleanup (Optional)\n",
    "\n",
    "Uncomment to delete the memory resource when done."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment to delete memory resource using boto3\n",
    "# try:\n",
    "#     client.delete_memory(memoryId=memory_id, clientToken=str(uuid.uuid4()))\n",
    "#     logger.info(f\"‚úÖ Successfully deleted memory: {memory_id}\")\n",
    "# except Exception as e:\n",
    "#     logger.error(f\"Error deleting memory: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
